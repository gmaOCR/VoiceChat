# üéì VoiceChat - Apprentissage Bilingue Vocal

Application d'apprentissage de langues par conversation vocale interactive avec IA.

## üåü Fonctionnalit√©s

- **Apprentissage bilingue naturel** : L'IA r√©pond dans votre langue maternelle et vous fait pratiquer dans la langue cible
- **Reconnaissance vocale** : Whisper large-v3-turbo (GPU distant)
- **IA p√©dagogue** : LLM adapt√© au contexte d'apprentissage
- **Synth√®se vocale** : TTS natif en fran√ßais et russe
- **R√©ponses segment√©es** : Audio multilingue pour une immersion progressive

## üéØ Principe

**√âtudiant fran√ßais apprenant le russe** :
- Vous demandez en fran√ßais ‚Üí L'IA explique en fran√ßais + exemples en russe
- Vous pratiquez en russe ‚Üí L'IA donne feedback en fran√ßais + correction en russe

**C'est comme avoir un professeur bilingue qui s'adapte √† vous !**

## üèóÔ∏è Architecture

```
Frontend (HTML/JS)
    ‚Üì [audio + langues]
Backend FastAPI
    ‚Üì transcription
Whisper API (mars.gregorymariani.com:8001)
    ‚Üì texte utilisateur
LLM Mistral (Ollama local)
    ‚Üì segments bilingues
TTS Edge-TTS
    ‚Üì fichiers audio
Frontend
    ‚Üì lecture s√©quentielle
```

## üöÄ Installation

```bash
# Cloner le projet
git clone [repo-url]
cd VoiceChat

# Cr√©er environnement virtuel
python3 -m venv venv
source venv/bin/activate

# Installer d√©pendances
pip install -r requirements.txt

# Lancer l'application
python main.py
```

Acc√®s : http://localhost:8000

## ‚öôÔ∏è Configuration

### Services Requis

1. **Ollama** (LLM local) : `http://192.168.1.28:11434`
   - Mod√®le : `mistral:latest`
   
2. **Whisper API** (distant) : `http://mars.gregorymariani.com:8001`
   - Mod√®le : `openai/whisper-large-v3-turbo`

### Variables (services.py)

```python
OLLAMA_URL = "http://192.168.1.28:11434"
MODEL_NAME = "mistral:latest"
WHISPER_API_URL = "http://mars.gregorymariani.com:8001"
```

## üìã API

### POST /chat

**Request**
```json
{
  "audio": "fichier.webm",
  "source_lang": "fr",    // Langue maternelle
  "target_lang": "ru"     // Langue √† apprendre
}
```

**Response**
```json
{
  "user_text": "Comment dit-on bonjour",
  "segments": [
    {"lang": "fr", "text": "En russe on dit"},
    {"lang": "ru", "text": "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ"}
  ],
  "audio_segments": [
    {"lang": "fr", "audio_url": "/audio/xxx_seg0_fr.mp3"},
    {"lang": "ru", "audio_url": "/audio/xxx_seg1_ru.mp3"}
  ]
}
```

## üìä Performance

| √âtape | Temps | Optimisations |
|-------|-------|---------------|
| Upload audio | ~0.05s | - |
| STT (Whisper) | ~2s | GPU distant |
| LLM (Mistral) | ~3-4s | Prompt optimis√© (-56% tokens) |
| TTS (Edge) | ~1-2s | - |
| **TOTAL** | **~6-8s** | -40% vs version initiale |

## üßπ Code Qualit√©

- **260 lignes** de code total (vs 437 avant refactorisation)
- **-40% de complexit√©** sur les fonctions critiques
- **Prompt -57%** plus court et clair
- **0 erreurs** de linting

## üéì Exemples d'Usage

### Cas 1 : Question en fran√ßais
```
üé§ "Comment dit-on au revoir en russe"

üîä [FR] "En russe on dit"
üîä [RU] "–î–æ —Å–≤–∏–¥–∞–Ω–∏—è"
üîä [FR] "C'est formel et poli"
```

### Cas 2 : Pratique en russe
```
üé§ "–î–æ–±—Ä–æ–µ —É—Ç—Ä–æ"

üîä [FR] "Parfait"
üîä [RU] "–ö–∞–∫ –¥–µ–ª–∞"
üîä [FR] "Maintenant demande comment √ßa va"
```

## üõ†Ô∏è D√©veloppement

### Structure des Fichiers

```
VoiceChat/
‚îú‚îÄ‚îÄ main.py              # API FastAPI
‚îú‚îÄ‚îÄ services.py          # STT, LLM, TTS
‚îú‚îÄ‚îÄ whisper_server.py    # Serveur Whisper distant
‚îú‚îÄ‚îÄ requirements.txt     # D√©pendances Python
‚îú‚îÄ‚îÄ static/
‚îÇ   ‚îú‚îÄ‚îÄ index.html       # Interface utilisateur
‚îÇ   ‚îú‚îÄ‚îÄ app.js           # Logique frontend
‚îÇ   ‚îî‚îÄ‚îÄ style.css        # Styles
‚îú‚îÄ‚îÄ audio_cache/         # Fichiers MP3 g√©n√©r√©s
‚îî‚îÄ‚îÄ temp_uploads/        # Upload temporaire
```

### Tests

```bash
# Tester serveur Whisper
python test_whisper_server.py

# Tester l'application compl√®te
# 1. Lancer main.py
# 2. Ouvrir http://localhost:8000
# 3. Parler dans le micro
```

## üìö Documentation

- **REFACTORING_BILINGUE.md** : D√©tails de la refactorisation et logique p√©dagogique

## ü§ù Contribution

Am√©liorations futures possibles :
- Support d'autres langues (ES, DE, IT...)
- Mode streaming pour r√©ponses plus rapides
- Cache LLM pour questions fr√©quentes
- Interface mobile responsive

## üìÑ Licence

[Votre licence ici]

---

**Note** : Ce projet n√©cessite un serveur Ollama local et un serveur Whisper distant pour fonctionner. - AI Language Tutor üéìüó£Ô∏è

> Chatbot vocal multilingue intelligent avec segmentation audio et d√©tection de langue automatique

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.115+-green.svg)](https://fastapi.tiangolo.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## üåü Caract√©ristiques Principales

### üéØ Segmentation Audio Multilingue
- **D√©tection automatique** de la langue d'input (fran√ßais/russe)
- **G√©n√©ration audio segment√©e** : chaque langue utilise sa propre voix native
- **Lecture s√©quentielle** fluide des segments audio
- **Pas de r√©p√©tition** inutile de l'input utilisateur

### üß† Intelligence Artificielle
- **STT (Speech-to-Text)** : Whisper (OpenAI)
- **LLM** : Llama 3.1 8B (via Ollama)
- **TTS (Text-to-Speech)** : Edge-TTS (voix natives FR/RU)

### üé® Interface Utilisateur
- **Design moderne** : Mode sombre √©l√©gant
- **Indicateurs visuels** : Drapeaux et noms de langue color√©s
- **Enregistrement simple** : Maintenir le bouton pour parler
- **Responsive** : Fonctionne sur mobile et desktop

---

## üöÄ D√©marrage Rapide

### Pr√©requis
- Python 3.8+
- Ollama install√© et configur√©
- Microphone fonctionnel

### Installation

```bash
# Cloner le projet
git clone https://github.com/gmaOCR/VoiceChat.git
cd VoiceChat

# Installer les d√©pendances
pip install -r requirements.txt

# Lancer le serveur
python main.py
```

### Acc√®s
Ouvrir votre navigateur √† : **http://localhost:8000**

---

## üìñ Documentation

- **[QUICKSTART.md](QUICKSTART.md)** - Guide d'utilisation complet
- **[IMPLEMENTATION_NOTES.md](IMPLEMENTATION_NOTES.md)** - Architecture technique
- **[CHANGELOG.md](CHANGELOG.md)** - Historique des versions

---

## üéØ Cas d'Usage

### Sc√©nario 1 : Pratiquer le Fran√ßais
**Vous :** üá∑üá∫ (Native) | **Cible :** üá´üá∑ (Apprentissage)

**Vous dites :** _"Bonjour, comment √ßa va ?"_

**AI r√©pond :**
- üá∑üá∫ –û—Ç–ª–∏—á–Ω–æ! –í—ã —Å–∫–∞–∑–∞–ª–∏ —ç—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ.
- üá´üá∑ √áa va bien, merci ! Et vous ?

**Audio :** üîä Voix russe ‚Üí üîä Voix fran√ßaise

---

### Sc√©nario 2 : Demander de l'Aide
**Vous dites :** _"–ö–∞–∫ —Å–ø—Ä–æ—Å–∏—Ç—å, –≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤–æ–∫–∑–∞–ª?"_ (en russe)

**AI r√©pond :**
- üá∑üá∫ –ß—Ç–æ–±—ã —Å–ø—Ä–æ—Å–∏—Ç—å –≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤–æ–∫–∑–∞–ª, —Å–∫–∞–∂–∏—Ç–µ...
- üá´üá∑ O√π est la gare ?

**Audio :** üîä Explication en russe ‚Üí üîä Exemple en fran√ßais

---

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Utilisateur ‚îÇ Parle (Audio)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Whisper (STT)  ‚îÇ Transcription
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Ollama (LLM)      ‚îÇ D√©tection langue + G√©n√©ration segments
‚îÇ   Llama 3.1 8B      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ segments: [        ‚îÇ
    ‚îÇ   {lang: ru, ...}  ‚îÇ
    ‚îÇ   {lang: fr, ...}  ‚îÇ
    ‚îÇ ]                  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Edge-TTS               ‚îÇ
‚îÇ  ‚îú‚îÄ segment_0_ru.mp3   ‚îÇ ‚Üê Voix russe
‚îÇ  ‚îî‚îÄ segment_1_fr.mp3   ‚îÇ ‚Üê Voix fran√ßaise
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   Frontend   ‚îÇ Lecture s√©quentielle
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üõ†Ô∏è Technologies

| Composant | Technologie | R√¥le |
|---|---|---|
| **Backend** | FastAPI | API REST |
| **STT** | Faster-Whisper | Transcription audio |
| **LLM** | Ollama (Llama 3.1) | Correction & R√©ponse IA |
| **TTS** | Edge-TTS | G√©n√©ration audio |
| **Frontend** | Vanilla JS | Interface utilisateur |
| **Styling** | CSS3 | Design moderne |

---

## üìä Structure du Projet

```
VoiceChat/
‚îú‚îÄ‚îÄ main.py                    # Serveur FastAPI
‚îú‚îÄ‚îÄ services.py                # Services STT/LLM/TTS
‚îú‚îÄ‚îÄ test_segmentation.py       # Tests unitaires
‚îú‚îÄ‚îÄ requirements.txt           # D√©pendances Python
‚îÇ
‚îú‚îÄ‚îÄ static/
‚îÇ   ‚îú‚îÄ‚îÄ index.html             # Interface utilisateur
‚îÇ   ‚îú‚îÄ‚îÄ app.js                 # Logique frontend
‚îÇ   ‚îî‚îÄ‚îÄ style.css              # Styles
‚îÇ
‚îú‚îÄ‚îÄ audio_cache/               # Fichiers audio g√©n√©r√©s
‚îú‚îÄ‚îÄ temp_uploads/              # Uploads temporaires
‚îÇ
‚îú‚îÄ‚îÄ QUICKSTART.md              # Guide utilisateur
‚îú‚îÄ‚îÄ IMPLEMENTATION_NOTES.md    # Documentation technique
‚îú‚îÄ‚îÄ CHANGELOG.md               # Historique versions
‚îî‚îÄ‚îÄ README.md                  # Ce fichier
```

---

## üß™ Tests

### Test Manuel
```bash
# Lancer le serveur
python main.py

# Dans un autre terminal
python test_segmentation.py
```

### V√©rification
- ‚úÖ D√©tection de langue fonctionne
- ‚úÖ Segments g√©n√©r√©s correctement
- ‚úÖ Audio cr√©√© pour chaque segment
- ‚úÖ Lecture s√©quentielle fluide

---

## üé® Aper√ßu

### Interface Principale
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        Voice Chatbot                  ‚îÇ
‚îÇ                                       ‚îÇ
‚îÇ  üá´üá∑ Je parle Fran√ßais (Apprendre Russe) ‚îÇ
‚îÇ  üá∑üá∫ –Ø –≥–æ–≤–æ—Ä—é –ø–æ-—Ä—É—Å—Å–∫–∏ (Apprendre Fran√ßais) ‚îÇ
‚îÇ                                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                       ‚îÇ
‚îÇ  User: Bonjour, comment √ßa va ?       ‚îÇ
‚îÇ                                       ‚îÇ
‚îÇ  ‚úì Correction: [si n√©cessaire]        ‚îÇ
‚îÇ                                       ‚îÇ
‚îÇ  üá∑üá∫ –†—É—Å—Å–∫–∏–π: –û—Ç–ª–∏—á–Ω–æ!                ‚îÇ
‚îÇ  üá´üá∑ Fran√ßais: √áa va bien, merci !    ‚îÇ
‚îÇ                                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ            üéôÔ∏è                         ‚îÇ
‚îÇ          Pr√™t                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîß Configuration

### Changer le Mod√®le LLM
√âditer `services.py` :
```python
MODEL_NAME = "mistral:latest"  # ou autre mod√®le
```

### Changer les Voix TTS
√âditer `services.py` :
```python
voice = "fr-FR-DeniseNeural" if language == "fr" else "ru-RU-DmitryNeural"
```

Liste des voix disponibles :
```bash
edge-tts --list-voices | grep -E "fr-FR|ru-RU"
```

### Configurer Ollama
√âditer `services.py` :
```python
OLLAMA_URL = "http://localhost:11434"  # Votre URL Ollama
```

---

## üêõ D√©pannage

### Probl√®me : Audio ne se g√©n√®re pas
**Solution :** V√©rifier que `edge-tts` fonctionne
```bash
edge-tts --text "Test" --voice fr-FR-DeniseNeural --write-media test.mp3
```

### Probl√®me : LLM ne r√©pond pas
**Solution :** V√©rifier la connexion Ollama
```bash
curl http://localhost:11434/api/tags
```

### Probl√®me : Microphone non d√©tect√©
**Solution :** Autoriser l'acc√®s micro dans le navigateur (HTTPS requis en production)

---

## üìà Roadmap

### v2.1 (Court Terme)
- [ ] Cache des r√©ponses fr√©quentes
- [ ] Nettoyage automatique audio_cache/
- [ ] Export de conversations

### v3.0 (Moyen Terme)
- [ ] Support multi-langues (ES, DE, IT, ZH)
- [ ] Persistance de conversation
- [ ] Statistiques de progression

### v4.0 (Long Terme)
- [ ] Mode hors-ligne complet
- [ ] Application mobile native
- [ ] Gamification de l'apprentissage

---

## ü§ù Contribution

Les contributions sont les bienvenues ! Voici comment participer :

1. Fork le projet
2. Cr√©er une branche (`git checkout -b feature/AmazingFeature`)
3. Commit vos changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

---

## üìÑ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de d√©tails.

---

## üë®‚Äçüíª Auteur

**gmaOCR**
- GitHub: [@gmaOCR](https://github.com/gmaOCR)

---

## üôè Remerciements

- [OpenAI Whisper](https://github.com/openai/whisper) - STT
- [Ollama](https://ollama.ai/) - LLM local
- [Edge-TTS](https://github.com/rany2/edge-tts) - TTS gratuit
- [FastAPI](https://fastapi.tiangolo.com/) - Framework web moderne

---

## üìù Notes

### Performances
- **Latence typique** : 3-5 secondes (STT + LLM + TTS)
- **Pr√©cision STT** : >90% pour audio clair
- **Qualit√© TTS** : Voix naturelles natives

### Limitations Connues
- N√©cessite connexion internet (STT, LLM, TTS)
- Supporte uniquement FR/RU actuellement
- Pas de persistance de session

### Am√©liorations vs Pr√©c√©dentes Versions
- ‚úÖ **Audio segment√©** : Voix appropri√©es par langue
- ‚úÖ **Pas de r√©p√©tition** : Input utilisateur non vocalis√©
- ‚úÖ **Indicateurs visuels** : Drapeaux et couleurs
- ‚úÖ **Architecture propre** : Code modulaire et testable

---

**‚≠ê N'oubliez pas de donner une √©toile si ce projet vous aide ! ‚≠ê**
